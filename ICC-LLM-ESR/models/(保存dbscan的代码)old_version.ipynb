{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b16ae4-d0b9-49d8-879e-b54c18739393",
   "metadata": {},
   "source": [
    "LLMESR.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670dbca8-3941-4d50-8d58-ac58bb4c785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here put the import lib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.DualLLMSRS import DualLLMSASRec, DualLLMGRU4Rec, DualLLMBert4Rec\n",
    "from models.utils import Contrastive_Loss2, ClusterHandler  # 新增导入\n",
    "\n",
    "\n",
    "\n",
    "class LLMESR_SASRec(DualLLMSASRec):\n",
    "\n",
    "    def __init__(self, user_num, item_num, device, args):\n",
    "\n",
    "        super().__init__(user_num, item_num, device, args)\n",
    "        self.alpha = args.alpha\n",
    "        self.user_sim_func = args.user_sim_func\n",
    "        self.item_reg = args.item_reg\n",
    "        self.gamma = args.gamma  # 聚类约束强度\n",
    "\n",
    "        # 初始化聚类处理器\n",
    "        self.cluster_handler = ClusterHandler(args.dataset, args.hidden_size, device)\n",
    "\n",
    "        if self.user_sim_func == \"cl\":\n",
    "            self.align = Contrastive_Loss2()\n",
    "        elif self.user_sim_func == \"kd\":\n",
    "            self.align = nn.MSELoss()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        self.projector1 = nn.Linear(2*args.hidden_size, 2*args.hidden_size)\n",
    "        self.projector2 = nn.Linear(2*args.hidden_size, 2*args.hidden_size)\n",
    "\n",
    "        if self.item_reg:\n",
    "            self.beta = args.beta\n",
    "            self.reg = Contrastive_Loss2()\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "                seq, \n",
    "                pos, \n",
    "                neg, \n",
    "                positions,\n",
    "                **kwargs):\n",
    "        \n",
    "        loss = super().forward(seq, pos, neg, positions, **kwargs)  # get the original loss\n",
    "        \n",
    "        log_feats = self.log2feats(seq, positions)[:, -1, :]\n",
    "        sim_seq, sim_positions = kwargs[\"sim_seq\"].view(-1, seq.shape[1]), kwargs[\"sim_positions\"].view(-1, seq.shape[1])\n",
    "        sim_num = kwargs[\"sim_seq\"].shape[1]\n",
    "        sim_log_feats = self.log2feats(sim_seq, sim_positions)[:, -1, :]    # (bs*sim_num, hidden_size)\n",
    "        sim_log_feats = sim_log_feats.detach().view(seq.shape[0], sim_num, -1)  # (bs, sim_num, hidden_size)\n",
    "        sim_log_feats = torch.mean(sim_log_feats, dim=1)\n",
    "\n",
    "        if self.user_sim_func == \"cl\":\n",
    "            # align_loss = self.align(self.projector1(log_feats), self.projector2(sim_log_feats))\n",
    "            align_loss = self.align(log_feats, sim_log_feats)\n",
    "        elif self.user_sim_func == \"kd\":\n",
    "            align_loss = self.align(log_feats, sim_log_feats)\n",
    "\n",
    "        if self.item_reg:\n",
    "            unfold_item_id = torch.masked_select(seq, seq>0)\n",
    "            llm_item_emb = self.adapter(self.llm_item_emb(unfold_item_id))\n",
    "            id_item_emb = self.id_item_emb(unfold_item_id)\n",
    "            reg_loss = self.reg(llm_item_emb, id_item_emb)\n",
    "            loss += self.beta * reg_loss\n",
    "\n",
    "        # 计算聚类约束损失\n",
    "        item_ids = seq[seq > 0] # 有效物品ID\n",
    "        item_embeddings = self.id_item_emb(item_ids) # 获取物品嵌入\n",
    "        cluster_loss = self.cluster_handler.calculate_cluster_loss(item_ids, item_embeddings)\n",
    "        loss += self.gamma * cluster_loss\n",
    "\n",
    "        loss += self.alpha * align_loss\n",
    "\n",
    "        return loss\n",
    "    \n",
    "\n",
    "\n",
    "class LLMESR_GRU4Rec(DualLLMGRU4Rec):\n",
    "\n",
    "    def __init__(self, user_num, item_num, device, args):\n",
    "\n",
    "        super().__init__(user_num, item_num, device, args)\n",
    "        self.alpha = args.alpha\n",
    "        self.user_sim_func = args.user_sim_func\n",
    "        self.item_reg = args.item_reg\n",
    "        self.gamma = args.gamma  # 聚类约束强度\n",
    "\n",
    "        # 初始化聚类处理器\n",
    "        self.cluster_handler = ClusterHandler(args.dataset, args.hidden_size, device)\n",
    "\n",
    "        if self.user_sim_func == \"cl\":\n",
    "            self.align = Contrastive_Loss2()\n",
    "        elif self.user_sim_func == \"kd\":\n",
    "            self.align = nn.MSELoss()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        self.projector1 = nn.Linear(2*args.hidden_size, 2*args.hidden_size)\n",
    "        self.projector2 = nn.Linear(2*args.hidden_size, 2*args.hidden_size)\n",
    "\n",
    "        if self.item_reg:\n",
    "            self.beta = args.beta\n",
    "            self.reg = Contrastive_Loss2()\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "                seq, \n",
    "                pos, \n",
    "                neg, \n",
    "                positions,\n",
    "                **kwargs):\n",
    "        \n",
    "        loss = super().forward(seq, pos, neg, positions, **kwargs)  # get the original loss\n",
    "        \n",
    "        log_feats = self.log2feats(seq)[:, -1, :]\n",
    "        sim_seq, sim_positions = kwargs[\"sim_seq\"].view(-1, seq.shape[1]), kwargs[\"sim_positions\"].view(-1, seq.shape[1])\n",
    "        sim_num = kwargs[\"sim_seq\"].shape[1]\n",
    "        sim_log_feats = self.log2feats(sim_seq)[:, -1, :]    # (bs*sim_num, hidden_size)\n",
    "        sim_log_feats = sim_log_feats.detach().view(seq.shape[0], sim_num, -1)  # (bs, sim_num, hidden_size)\n",
    "        sim_log_feats = torch.mean(sim_log_feats, dim=1)\n",
    "\n",
    "        if self.user_sim_func == \"cl\":\n",
    "            # align_loss = self.align(self.projector1(log_feats), self.projector2(sim_log_feats))\n",
    "            align_loss = self.align(log_feats, sim_log_feats)\n",
    "        elif self.user_sim_func == \"kd\":\n",
    "            align_loss = self.align(log_feats, sim_log_feats)\n",
    "\n",
    "        if self.item_reg:\n",
    "            unfold_item_id = torch.masked_select(seq, seq>0)\n",
    "            llm_item_emb = self.adapter(self.llm_item_emb(unfold_item_id))\n",
    "            id_item_emb = self.id_item_emb(unfold_item_id)\n",
    "            reg_loss = self.reg(llm_item_emb, id_item_emb)\n",
    "            loss += self.beta * reg_loss\n",
    "\n",
    "        # 计算聚类约束损失\n",
    "        item_ids = seq[seq > 0] # 有效物品ID\n",
    "        item_embeddings = self.id_item_emb(item_ids) # 获取物品嵌入\n",
    "        cluster_loss = self.cluster_handler.calculate_cluster_loss(item_ids, item_embeddings)\n",
    "        loss += self.gamma * cluster_loss\n",
    "\n",
    "        loss += self.alpha * align_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "class LLMESR_Bert4Rec(DualLLMBert4Rec):\n",
    "\n",
    "    def __init__(self, user_num, item_num, device, args):\n",
    "\n",
    "        super().__init__(user_num, item_num, device, args)\n",
    "        self.alpha = args.alpha\n",
    "        self.user_sim_func = args.user_sim_func\n",
    "        self.item_reg = args.item_reg\n",
    "        self.gamma = args.gamma  # 聚类约束强度超参数\n",
    "\n",
    "        # 初始化聚类处理器\n",
    "        self.cluster_handler = ClusterHandler(args.dataset, args.hidden_size, device)\n",
    "\n",
    "\n",
    "        if self.user_sim_func == \"cl\":\n",
    "            self.align = Contrastive_Loss2()\n",
    "        elif self.user_sim_func == \"kd\":\n",
    "            self.align = nn.MSELoss()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        self.projector1 = nn.Linear(2*args.hidden_size, 2*args.hidden_size)\n",
    "        self.projector2 = nn.Linear(2*args.hidden_size, 2*args.hidden_size)\n",
    "\n",
    "        if self.item_reg:\n",
    "            self.reg = Contrastive_Loss2()\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "                seq, \n",
    "                pos, \n",
    "                neg, \n",
    "                positions,\n",
    "                **kwargs):\n",
    "        \n",
    "        loss = super().forward(seq, pos, neg, positions, **kwargs)  # get the original loss\n",
    "        \n",
    "        log_feats = self.log2feats(seq, positions)[:, -1, :]\n",
    "        sim_seq, sim_positions = kwargs[\"sim_seq\"].view(-1, seq.shape[1]), kwargs[\"sim_positions\"].view(-1, seq.shape[1])\n",
    "        sim_num = kwargs[\"sim_seq\"].shape[1]\n",
    "        sim_log_feats = self.log2feats(sim_seq, sim_positions)[:, -1, :]\n",
    "        sim_log_feats = sim_log_feats.detach().view(seq.shape[0], sim_num, -1)  # (bs, sim_num, hidden_size)\n",
    "        sim_log_feats = torch.mean(sim_log_feats, dim=1)\n",
    "\n",
    "        if self.user_sim_func == \"cl\":\n",
    "            # align_loss = self.align(self.projector1(log_feats), self.projector2(sim_log_feats))\n",
    "            align_loss = self.align(log_feats, sim_log_feats)\n",
    "        elif self.user_sim_func == \"kd\":\n",
    "            align_loss = self.align(log_feats, sim_log_feats)\n",
    "\n",
    "        # 计算聚类约束损失（适配Bert4Rec的特殊处理）\n",
    "        cluster_loss = self.calculate_cluster_loss(seq)\n",
    "\n",
    "        # 整合所有损失\n",
    "        loss += self.gamma * cluster_loss  # 聚类约束损失\n",
    "        loss += self.alpha * align_loss\n",
    "\n",
    "        return loss\n",
    "        \n",
    "    def calculate_cluster_loss(self, seq):\n",
    "        #1\n",
    "        valid_mask = (seq > 0) & (seq != self.mask_token)        # 过滤掉 PAD=0 和 MASK\n",
    "        item_ids   = seq[valid_mask]                             # 1-D tensor\n",
    "        if item_ids.numel() == 0:                                # 这一批全是 PAD/MASK\n",
    "            return torch.tensor(0.0, device=seq.device)\n",
    "        # ---------- 2) 再过滤聚类表里没有的 item——id ----------\n",
    "        # 防止越界导致 device-side assert\n",
    "        max_id_in_cluster = self.cluster_handler.item_cluster.size(0) - 1\n",
    "        item_ids = item_ids[item_ids <= max_id_in_cluster]\n",
    "\n",
    "        if item_ids.numel() == 0:                                # 都被过滤掉\n",
    "            return torch.tensor(0.0, device=seq.device)\n",
    "        # ---------- 3) 查嵌入并计算聚类损失 ----------\n",
    "        item_embeddings = self.id_item_emb(item_ids)\n",
    "        cluster_loss    = self.cluster_handler.calculate_cluster_loss(item_ids, item_embeddings)\n",
    "        return cluster_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b1c18-9b21-419d-a759-02a3de48599d",
   "metadata": {},
   "source": [
    "utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74193ce5-5e3d-4637-ba53-bf1c697e9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here put the import lib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pickle\n",
    "from pathlib import Path \n",
    "\n",
    "# 新增：聚类信息处理类\n",
    "class ClusterHandler(nn.Module):\n",
    "    \"\"\"处理聚类信息的工具类，用于获取聚类中心和计算聚类损失\"\"\"\n",
    "    def __init__(self, dataset, hidden_size, device):\n",
    "        super().__init__()\n",
    "        ####################################\n",
    "        #self.item2center = torch.load(Path(dataset)/\"item_cluster.pt\",\n",
    "                                     # map_location=device)   # 原本的字段\n",
    "        #self.item_cluster = self.item2center\n",
    "        cluster_path = Path(\"data\") / dataset / \"item_cluster.pt\"\n",
    "        self.item_cluster = torch.load(cluster_path, map_location=device)\n",
    "        ########################\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.load_cluster_info(dataset)\n",
    "        \n",
    "        # 定义聚类中心映射层（8维→d维）\n",
    "        self.cluster_projection = nn.Linear(8, hidden_size)\n",
    "        # 冻结映射层参数\n",
    "        for param in self.cluster_projection.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def load_cluster_info(self, dataset):\n",
    "        \"\"\"加载聚类标签和中心，并转换为张量\"\"\"\n",
    "        data_dir = f'data/{dataset}/handled/'\n",
    "        # 读取item聚类标签（含噪声）\n",
    "        with open(f'{data_dir}/item_cluster_labels.pkl', 'rb') as f:\n",
    "            self.item_cluster_labels = torch.tensor(pickle.load(f), dtype=torch.long, device=self.device)\n",
    "        # 读取8维聚类中心\n",
    "        with open(f'{data_dir}/cluster_centers_8d.pkl', 'rb') as f:\n",
    "            cluster_centers_8d = pickle.load(f)\n",
    "        # 将中心数据转换为PyTorch张量\n",
    "        num_clusters = len(cluster_centers_8d)\n",
    "        self.cluster_centers_8d = torch.zeros(num_clusters, 8, device=self.device)\n",
    "        for c_id, center in cluster_centers_8d.items():\n",
    "            self.cluster_centers_8d[c_id] = torch.tensor(center, dtype=torch.float32, device=self.device)\n",
    "\n",
    "    def get_cluster_center(self, item_ids):\n",
    "        \"\"\"获取item对应的聚类中心（映射到d维）\"\"\"\n",
    "        # 获取聚类标签\n",
    "        cluster_labels = self.item_cluster_labels[item_ids]\n",
    "        # 提取非噪声item的8维中心\n",
    "        non_noise_mask = cluster_labels != -1 #过滤噪声物品（标签为-1）\n",
    "        non_noise_indices = torch.where(non_noise_mask)[0]\n",
    "        non_noise_labels = cluster_labels[non_noise_indices]\n",
    "        # 仅对非噪声物品：获取8维中心，并映射到d维\n",
    "        cluster_centers_8d = self.cluster_centers_8d[non_noise_labels]\n",
    "        cluster_centers_d = self.cluster_projection(cluster_centers_8d)\n",
    "        # 创建全零张量（与协作嵌入维度一致）\n",
    "        batch_size = item_ids.size(0)\n",
    "        centers_d = torch.zeros(batch_size, self.hidden_size, device=item_ids.device)\n",
    "        # 将非噪声item的中心填入结果，为噪声物品返回零向量\n",
    "        centers_d[non_noise_indices] = cluster_centers_d\n",
    "        return centers_d, non_noise_mask\n",
    "\n",
    "    def calculate_cluster_loss(self, item_ids, item_embeddings):\n",
    "        \"\"\"计算非噪声item的聚类约束损失\"\"\"\n",
    "        if item_ids.numel() == 0:\n",
    "            return torch.tensor(0.0, device=self.device)\n",
    "        \n",
    "        # 获取item对应的聚类中心（d维）和非噪声掩码\n",
    "        centers_d, non_noise_mask = self.get_cluster_center(item_ids)\n",
    "        \n",
    "        # 仅计算非噪声item的损失\n",
    "        if non_noise_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=self.device)\n",
    "        \n",
    "        # 计算非噪声item的L2损失\n",
    "        non_noise_embeddings = item_embeddings[non_noise_mask]\n",
    "        non_noise_centers = centers_d[non_noise_mask]\n",
    "        cluster_loss = torch.mean(torch.norm(non_noise_embeddings - non_noise_centers, p=2, dim=1)**2)\n",
    "        \n",
    "        return cluster_loss\n",
    "\n",
    "class PointWiseFeedForward(torch.nn.Module):\n",
    "    def __init__(self, hidden_units, dropout_rate):\n",
    "\n",
    "        super(PointWiseFeedForward, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n",
    "        self.dropout1 = torch.nn.Dropout(p=dropout_rate)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n",
    "        self.dropout2 = torch.nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.dropout2(self.conv2(self.relu(self.dropout1(self.conv1(inputs.transpose(-1, -2))))))\n",
    "        outputs = outputs.transpose(-1, -2) # as Conv1D requires (N, C, Length)\n",
    "        outputs += inputs\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "\n",
    "class PointWiseFeedForward(torch.nn.Module):\n",
    "    def __init__(self, hidden_units, dropout_rate):\n",
    "\n",
    "        super(PointWiseFeedForward, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n",
    "        self.dropout1 = torch.nn.Dropout(p=dropout_rate)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n",
    "        self.dropout2 = torch.nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.dropout2(self.conv2(self.relu(self.dropout1(self.conv1(inputs.transpose(-1, -2))))))\n",
    "        outputs = outputs.transpose(-1, -2) # as Conv1D requires (N, C, Length)\n",
    "        outputs += inputs\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "\n",
    "class Contrastive_Loss2(nn.Module):\n",
    "\n",
    "    def __init__(self, tau=1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.temperature = tau\n",
    "\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        \n",
    "        logits = (X @ Y.T) / self.temperature\n",
    "        X_similarity = Y @ Y.T\n",
    "        Y_similarity = X @ X.T\n",
    "        targets = F.softmax(\n",
    "            (X_similarity + Y_similarity) / 2 * self.temperature, dim=-1\n",
    "        )\n",
    "        X_loss = self.cross_entropy(logits, targets, reduction='none')\n",
    "        Y_loss = self.cross_entropy(logits.T, targets.T, reduction='none')\n",
    "        loss =  (Y_loss + X_loss) / 2.0 # shape: (batch_size)\n",
    "        return loss.mean()\n",
    "    \n",
    "\n",
    "    def cross_entropy(self, preds, targets, reduction='none'):\n",
    "\n",
    "        log_softmax = nn.LogSoftmax(dim=-1)\n",
    "        loss = (-targets * log_softmax(preds)).sum(1)\n",
    "        if reduction == \"none\":\n",
    "            return loss\n",
    "        elif reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "    \n",
    "\n",
    "\n",
    "class CalculateAttention(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "    def forward(self, Q, K, V, mask):\n",
    "\n",
    "        attention = torch.matmul(Q,torch.transpose(K, -1, -2))\n",
    "        # use mask\n",
    "        attention = attention.masked_fill_(mask, -1e9)\n",
    "        attention = torch.softmax(attention / sqrt(Q.size(-1)), dim=-1)\n",
    "        attention = torch.matmul(attention,V)\n",
    "        return attention\n",
    "\n",
    "\n",
    "\n",
    "class Multi_CrossAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    forward时，第一个参数用于计算query，第二个参数用于计算key和value\n",
    "    \"\"\"\n",
    "    def __init__(self,hidden_size,all_head_size,head_num):\n",
    "        super().__init__()\n",
    "        self.hidden_size    = hidden_size       # 输入维度\n",
    "        self.all_head_size  = all_head_size     # 输出维度\n",
    "        self.num_heads      = head_num          # 注意头的数量\n",
    "        self.h_size         = all_head_size // head_num\n",
    "\n",
    "        assert all_head_size % head_num == 0\n",
    "\n",
    "        # W_Q,W_K,W_V (hidden_size,all_head_size)\n",
    "        self.linear_q = nn.Linear(hidden_size, all_head_size, bias=False)\n",
    "        self.linear_k = nn.Linear(hidden_size, all_head_size, bias=False)\n",
    "        self.linear_v = nn.Linear(hidden_size, all_head_size, bias=False)\n",
    "        self.linear_output = nn.Linear(all_head_size, hidden_size)\n",
    "\n",
    "        # normalization\n",
    "        self.norm = sqrt(all_head_size)\n",
    "\n",
    "\n",
    "    def print(self):\n",
    "        print(self.hidden_size,self.all_head_size)\n",
    "        print(self.linear_k,self.linear_q,self.linear_v)\n",
    "    \n",
    "\n",
    "    def forward(self,x,y,log_seqs):\n",
    "        \"\"\"\n",
    "        cross-attention: x,y是两个模型的隐藏层，将x作为q的输入，y作为k和v的输入\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "\n",
    "        # q_s: [batch_size, num_heads, seq_length, h_size]\n",
    "        q_s = self.linear_q(x).view(batch_size, -1, self.num_heads, self.h_size).transpose(1,2)\n",
    "\n",
    "        # k_s: [batch_size, num_heads, seq_length, h_size]\n",
    "        k_s = self.linear_k(y).view(batch_size, -1, self.num_heads, self.h_size).transpose(1,2)\n",
    "\n",
    "        # v_s: [batch_size, num_heads, seq_length, h_size]\n",
    "        v_s = self.linear_v(y).view(batch_size, -1, self.num_heads, self.h_size).transpose(1,2)\n",
    "\n",
    "        # attention_mask = attention_mask.eq(0)\n",
    "        attention_mask = (log_seqs == 0).unsqueeze(1).repeat(1, log_seqs.size(1), 1).unsqueeze(1)\n",
    "\n",
    "        attention = CalculateAttention()(q_s,k_s,v_s,attention_mask)\n",
    "        # attention : [batch_size , seq_length , num_heads * h_size]\n",
    "        attention = attention.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.h_size)\n",
    "        \n",
    "        # output : [batch_size , seq_length , hidden_size]\n",
    "        output = self.linear_output(attention)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb90d64-52c4-4154-b99d-fafe563283ad",
   "metadata": {},
   "source": [
    "main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e004d-a220-4425-9b2d-b4bef64d81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here put the import lib\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from generators.generator import Seq2SeqGeneratorAllUser\n",
    "from generators.generator import GeneratorAllUser\n",
    "from generators.bert_generator import BertGeneratorAllUser\n",
    "from trainers.sequence_trainer import SeqTrainer\n",
    "from utils.utils import set_seed\n",
    "from utils.logger import Logger\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Required parameters\n",
    "parser.add_argument(\"--model_name\", \n",
    "                    default='llmesr_sasrec',\n",
    "                    choices=[\n",
    "                    \"llmesr_sasrec\", \"llmesr_bert4rec\", \"llmesr_gru4rec\",\n",
    "                    ],\n",
    "                    type=str, \n",
    "                    required=False,\n",
    "                    help=\"model name\")\n",
    "parser.add_argument(\"--dataset\", \n",
    "                    default=\"yelp\", \n",
    "                    choices=[\"yelp\", \"fashion\", \"beauty\",],  # preprocess by myself\n",
    "                    help=\"Choose the dataset\")\n",
    "parser.add_argument(\"--inter_file\",\n",
    "                    default=\"inter\",\n",
    "                    type=str,\n",
    "                    help=\"the name of interaction file\")\n",
    "parser.add_argument(\"--demo\", \n",
    "                    default=False, \n",
    "                    action='store_true', \n",
    "                    help='whether run demo')\n",
    "parser.add_argument(\"--pretrain_dir\",\n",
    "                    type=str,\n",
    "                    default=\"sasrec_seq\",\n",
    "                    help=\"the path that pretrained model saved in\")\n",
    "parser.add_argument(\"--output_dir\",\n",
    "                    default='./saved/',\n",
    "                    type=str,\n",
    "                    required=False,\n",
    "                    help=\"The output directory where the model checkpoints will be written.\")\n",
    "parser.add_argument(\"--check_path\",\n",
    "                    default='',\n",
    "                    type=str,\n",
    "                    help=\"the save path of checkpoints for different running\")\n",
    "parser.add_argument(\"--do_test\",\n",
    "                    default=False,\n",
    "                    action=\"store_true\",\n",
    "                    help=\"whehther run the test on the well-trained model\")\n",
    "parser.add_argument(\"--do_emb\",\n",
    "                    default=False,\n",
    "                    action=\"store_true\",\n",
    "                    help=\"save the user embedding derived from the SRS model\")\n",
    "parser.add_argument(\"--do_group\",\n",
    "                    default=False,\n",
    "                    action=\"store_true\",\n",
    "                    help=\"conduct the group test\")\n",
    "parser.add_argument(\"--keepon\",\n",
    "                    default=False,\n",
    "                    action=\"store_true\",\n",
    "                    help=\"whether keep on training based on a trained model\")\n",
    "parser.add_argument(\"--keepon_path\",\n",
    "                    type=str,\n",
    "                    default=\"normal\",\n",
    "                    help=\"the path of trained model for keep on training\")\n",
    "parser.add_argument(\"--clip_path\",\n",
    "                    type=str,\n",
    "                    default=\"\",\n",
    "                    help=\"the path to save the CLIP-pretrained embedding and adapter\")\n",
    "parser.add_argument(\"--ts_user\",\n",
    "                    type=int,\n",
    "                    default=10,\n",
    "                    help=\"the threshold to split the short and long seq\")\n",
    "parser.add_argument(\"--ts_item\",\n",
    "                    type=int,\n",
    "                    default=20,\n",
    "                    help=\"the threshold to split the long-tail and popular items\")\n",
    "\n",
    "# Model parameters\n",
    "parser.add_argument(\"--hidden_size\",\n",
    "                    default=64,\n",
    "                    type=int,\n",
    "                    help=\"the hidden size of embedding\")\n",
    "parser.add_argument(\"--trm_num\",\n",
    "                    default=2,\n",
    "                    type=int,\n",
    "                    help=\"the number of transformer layer\")\n",
    "parser.add_argument(\"--num_heads\",\n",
    "                    default=1,\n",
    "                    type=int,\n",
    "                    help=\"the number of heads in Trm layer\")\n",
    "parser.add_argument(\"--num_layers\",\n",
    "                    default=1,\n",
    "                    type=int,\n",
    "                    help=\"the number of GRU layers\")\n",
    "parser.add_argument(\"--cl_scale\",\n",
    "                    type=float,\n",
    "                    default=0.1,\n",
    "                    help=\"the scale for contastive loss\")\n",
    "parser.add_argument(\"--mask_crop_ratio\",\n",
    "                    type=float,\n",
    "                    default=0.3,\n",
    "                    help=\"the mask/crop ratio for CL4SRec\")\n",
    "parser.add_argument(\"--tau\",\n",
    "                    default=1,\n",
    "                    type=float,\n",
    "                    help=\"the temperature for contrastive loss\")\n",
    "parser.add_argument(\"--sse_ratio\",\n",
    "                    default=0.4,\n",
    "                    type=float,\n",
    "                    help=\"the sse ratio for SSE-PT model\")\n",
    "parser.add_argument(\"--dropout_rate\",\n",
    "                    default=0.5,\n",
    "                    type=float,\n",
    "                    help=\"the dropout rate\")\n",
    "parser.add_argument(\"--max_len\",\n",
    "                    default=200,\n",
    "                    type=int,\n",
    "                    help=\"the max length of input sequence\")\n",
    "parser.add_argument(\"--mask_prob\",\n",
    "                    type=float,\n",
    "                    default=0.4,\n",
    "                    help=\"the mask probability for training Bert model\")\n",
    "parser.add_argument(\"--aug\",\n",
    "                    default=False,\n",
    "                    action=\"store_true\",\n",
    "                    help=\"whether augment the sequence data\")\n",
    "parser.add_argument(\"--aug_seq\",\n",
    "                    default=False,\n",
    "                    action=\"store_true\",\n",
    "                    help=\"whether use the augmented data\")\n",
    "parser.add_argument(\"--aug_seq_len\",\n",
    "                    default=0,\n",
    "                    type=int,\n",
    "                    help=\"the augmented length for each sequence\")\n",
    "parser.add_argument(\"--aug_file\",\n",
    "                    default=\"inter\",\n",
    "                    type=str,\n",
    "                    help=\"the augmentation file name\")\n",
    "parser.add_argument(\"--train_neg\",\n",
    "                    default=1,\n",
    "                    type=int,\n",
    "                    help=\"the number of negative samples for training\")\n",
    "parser.add_argument(\"--test_neg\",\n",
    "                    default=100,\n",
    "                    type=int,\n",
    "                    help=\"the number of negative samples for test\")\n",
    "parser.add_argument(\"--suffix_num\",\n",
    "                    default=5,\n",
    "                    type=int,\n",
    "                    help=\"the suffix number for augmented sequence\")\n",
    "parser.add_argument(\"--prompt_num\",\n",
    "                    default=2,\n",
    "                    type=int,\n",
    "                    help=\"the number of prompts\")\n",
    "parser.add_argument(\"--freeze\",\n",
    "                    default=False,\n",
    "                    action=\"store_true\",\n",
    "                    help=\"whether freeze the pretrained architecture when finetuning\")\n",
    "parser.add_argument(\"--pg\",\n",
    "                    default=\"length\",\n",
    "                    choices=['length', 'attention'],\n",
    "                    type=str,\n",
    "                    help=\"choose the prompt generator\")\n",
    "parser.add_argument(\"--use_cross_att\",\n",
    "                    default=False,\n",
    "                    action=\"store_true\",\n",
    "                    help=\"whether add a cross-attention to interact the dual-view\")\n",
    "parser.add_argument(\"--alpha\",\n",
    "                    default=0.1,\n",
    "                    type=float,\n",
    "                    help=\"the weight of auxiliary loss\")\n",
    "parser.add_argument(\"--gamma\",\n",
    "                    default=0.1,\n",
    "                    type=float,\n",
    "                    help=\"the weight of cluster loss\")\n",
    "parser.add_argument(\"--user_sim_func\",\n",
    "                    default=\"kd\",\n",
    "                    type=str,\n",
    "                    help=\"the type of user similarity function to derive the loss\")\n",
    "parser.add_argument(\"--item_reg\",\n",
    "                    default=False,\n",
    "                    action=\"store_true\",\n",
    "                    help=\"whether regularize the item embedding by CL\")\n",
    "parser.add_argument(\"--beta\",\n",
    "                    default=0.1,\n",
    "                    type=float,\n",
    "                    help=\"the weight of regulation loss\")\n",
    "parser.add_argument(\"--sim_user_num\",\n",
    "                    default=10,\n",
    "                    type=int,\n",
    "                    help=\"the number of similar users for enhancement\")\n",
    "parser.add_argument(\"--split_backbone\",\n",
    "                    default=False,\n",
    "                    action=\"store_true\",\n",
    "                    help=\"whether use a split backbone\")\n",
    "parser.add_argument(\"--co_view\",\n",
    "                    default=False,\n",
    "                    action=\"store_true\",\n",
    "                    help=\"only use the collaborative view\")\n",
    "parser.add_argument(\"--se_view\",\n",
    "                    default=False,\n",
    "                    action=\"store_true\",\n",
    "                    help=\"only use the semantic view\")\n",
    "\n",
    "\n",
    "# Other parameters\n",
    "parser.add_argument(\"--train_batch_size\",\n",
    "                    default=512,\n",
    "                    type=int,\n",
    "                    help=\"Total batch size for training.\")\n",
    "parser.add_argument(\"--lr\",\n",
    "                    default=0.001,\n",
    "                    type=float,\n",
    "                    help=\"The initial learning rate for Adam.\")\n",
    "parser.add_argument(\"--l2\",\n",
    "                    default=0,\n",
    "                    type=float,\n",
    "                    help='The L2 regularization')\n",
    "parser.add_argument(\"--num_train_epochs\",\n",
    "                    default=100,\n",
    "                    type=float,\n",
    "                    help=\"Total number of training epochs to perform.\")\n",
    "parser.add_argument(\"--lr_dc_step\",\n",
    "                    default=1000,\n",
    "                    type=int,\n",
    "                    help='every n step, decrease the lr')\n",
    "parser.add_argument(\"--lr_dc\",\n",
    "                    default=0,\n",
    "                    type=float,\n",
    "                    help='how many learning rate to decrease')\n",
    "parser.add_argument(\"--patience\",\n",
    "                    type=int,\n",
    "                    default=20,\n",
    "                    help='How many steps to tolerate the performance decrease while training')\n",
    "parser.add_argument(\"--watch_metric\",\n",
    "                    type=str,\n",
    "                    default='NDCG@10',\n",
    "                    help=\"which metric is used to select model.\")\n",
    "parser.add_argument('--seed',\n",
    "                    type=int,\n",
    "                    default=42,\n",
    "                    help=\"random seed for different data split\")\n",
    "parser.add_argument(\"--no_cuda\",\n",
    "                    action='store_true',\n",
    "                    help=\"Whether not to use CUDA when available\")\n",
    "parser.add_argument('--gpu_id',\n",
    "                    default=0,\n",
    "                    type=int,\n",
    "                    help='The device id.')\n",
    "parser.add_argument('--num_workers',\n",
    "                    default=0,\n",
    "                    type=int,\n",
    "                    help='The number of workers in dataloader')\n",
    "parser.add_argument(\"--log\", \n",
    "                    default=False,\n",
    "                    action=\"store_true\",\n",
    "                    help=\"whether create a new log file\")\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "set_seed(args.seed) # fix the random seed\n",
    "args.output_dir = os.path.join(args.output_dir, args.dataset)\n",
    "args.pretrain_dir = os.path.join(args.output_dir, args.pretrain_dir)\n",
    "args.output_dir = os.path.join(args.output_dir, args.model_name)\n",
    "args.keepon_path = os.path.join(args.output_dir, args.keepon_path)\n",
    "args.output_dir = os.path.join(args.output_dir, args.check_path)    # if check_path is none, then without check_path\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    log_manager = Logger(args)  # initialize the log manager\n",
    "    logger, writer = log_manager.get_logger()    # get the logger\n",
    "    args.now_str = log_manager.get_now_str()\n",
    "\n",
    "    device = torch.device(\"cuda:\"+str(args.gpu_id) if torch.cuda.is_available()\n",
    "                          and not args.no_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "    # generator is used to manage dataset\n",
    "    if args.model_name in ['llmesr_gru4rec']:\n",
    "        generator = GeneratorAllUser(args, logger, device)\n",
    "    elif args.model_name in [\"llmesr_bert4rec\"]:\n",
    "        generator = BertGeneratorAllUser(args, logger, device)\n",
    "    elif args.model_name in [\"llmesr_sasrec\"]:\n",
    "        generator = Seq2SeqGeneratorAllUser(args, logger, device)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    trainer = SeqTrainer(args, logger, writer, device, generator)\n",
    "\n",
    "    if args.do_test:\n",
    "        trainer.test()\n",
    "    elif args.do_emb:\n",
    "        trainer.save_user_emb()\n",
    "    elif args.do_group:\n",
    "        trainer.test_group()\n",
    "    else:\n",
    "        trainer.train()\n",
    "\n",
    "    log_manager.end_log()   # delete the logger threads\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edde0c2-62ba-4167-8f4e-cd9fd2b752ef",
   "metadata": {},
   "source": [
    "保留hdbscan传统的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3e013-0551-41cb-90e9-a1304bf46481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here put the import lib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pickle\n",
    "from pathlib import Path \n",
    "\n",
    "# 新增：聚类信息处理类（支持传统聚类+模糊-密度约束）\n",
    "class ClusterHandler(nn.Module):\n",
    "    \"\"\"处理聚类信息的工具类，支持传统聚类损失和模糊-密度约束损失\"\"\"\n",
    "    def __init__(self, dataset, hidden_size, device, use_fuzzy=False):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.dataset = dataset  # 数据集名称（如\"fashion\"）\n",
    "        self.use_fuzzy = use_fuzzy  # 开关：是否启用模糊-密度约束\n",
    "\n",
    "        \n",
    "        # ---------------------- 1. 原有传统聚类相关初始化 ----------------------\n",
    "        # 加载传统聚类标签（item_cluster.pt，保留原有逻辑）\n",
    "        #cluster_path = Path(\"data\") / dataset / \"item_cluster.pt\"\n",
    "        #self.item_cluster = torch.load(cluster_path, map_location=device)\n",
    "        # 加载8维簇中心和聚类标签（原有load_cluster_info逻辑）\n",
    "        self.load_cluster_info(dataset)\n",
    "        # 传统聚类：8维→d维映射层（冻结参数）\n",
    "        self.cluster_projection = nn.Linear(8, hidden_size)\n",
    "        for param in self.cluster_projection.parameters():\n",
    "            param.requires_grad = False\n",
    "        # ---------------------- 1. 原有传统聚类相关初始化 ----------------------\n",
    "\n",
    "\n",
    "        \n",
    "        # ---------------------- 2. 新增：模糊-密度约束相关初始化 ----------------------\n",
    "        if self.use_fuzzy:\n",
    "            self._load_fuzzy_constraint_files()  # 加载模糊约束文件\n",
    "            self.fuzzy_m = 2.0  # 模糊指数（与之前计算一致，可改为参数传入）\n",
    "\n",
    "    def load_cluster_info(self, dataset):\n",
    "        \"\"\"原有逻辑：加载传统聚类的8维簇中心和标签\"\"\"\n",
    "        data_dir = f'data/{dataset}/handled/'\n",
    "        # 读取item聚类标签（含噪声，标签=-1）\n",
    "        with open(f'{data_dir}/item_cluster_labels.pkl', 'rb') as f:\n",
    "            self.item_cluster_labels = torch.tensor(pickle.load(f), dtype=torch.long, device=self.device)\n",
    "        # 读取8维聚类中心（传统聚类结果）\n",
    "        with open(f'{data_dir}/cluster_centers_8d.pkl', 'rb') as f:\n",
    "            cluster_centers_8d = pickle.load(f)\n",
    "        # 转换为Tensor（适配PyTorch）\n",
    "        num_clusters = len(cluster_centers_8d)\n",
    "        self.cluster_centers_8d = torch.zeros(num_clusters, 8, device=self.device)\n",
    "        for c_id, center in cluster_centers_8d.items():\n",
    "            self.cluster_centers_8d[c_id] = torch.tensor(center, dtype=torch.float32, device=self.device)\n",
    "\n",
    "    def _load_fuzzy_constraint_files(self):\n",
    "        \"\"\"新增：加载模糊-密度约束的核心文件（hdbscan_fuzzy_U.pkl、hdbscan_cluster_centers.pkl）\"\"\"\n",
    "        data_dir = Path(f'data/{self.dataset}/handled/')  # 与Fashion数据集路径对齐\n",
    "        # 1. 加载模糊隶属度向量（N个物品 × C个簇，N=4722 for Fashion）\n",
    "        fuzzy_U_path = data_dir / \"hdbscan_fuzzy_U.pkl\"\n",
    "        if not fuzzy_U_path.exists():\n",
    "            raise FileNotFoundError(f\"模糊隶属度文件不存在：{fuzzy_U_path}\")\n",
    "        with open(fuzzy_U_path, 'rb') as f:\n",
    "            fuzzy_U_np = pickle.load(f)\n",
    "        self.fuzzy_U = torch.tensor(fuzzy_U_np, dtype=torch.float32, device=self.device)\n",
    "\n",
    "        # 2. 加载加权簇中心（C个簇 × 64维，与hidden_size一致）\n",
    "        cluster_centers_path = data_dir / \"hdbscan_cluster_centers.pkl\"\n",
    "        if not cluster_centers_path.exists():\n",
    "            raise FileNotFoundError(f\"加权簇中心文件不存在：{cluster_centers_path}\")\n",
    "        with open(cluster_centers_path, 'rb') as f:\n",
    "            cluster_centers_np = pickle.load(f)\n",
    "        self.hdbscan_cluster_centers = torch.tensor(cluster_centers_np, dtype=torch.float32, device=self.device)\n",
    "        self.num_fuzzy_clusters = self.hdbscan_cluster_centers.shape[0]  # 模糊簇数量C\n",
    "\n",
    "    def get_cluster_center(self, item_ids):\n",
    "        \"\"\"原有逻辑：获取传统聚类的d维簇中心（8维→d维映射）\"\"\"\n",
    "        cluster_labels = self.item_cluster_labels[item_ids]\n",
    "        non_noise_mask = cluster_labels != -1\n",
    "        non_noise_indices = torch.where(non_noise_mask)[0]\n",
    "        non_noise_labels = cluster_labels[non_noise_indices]\n",
    "        \n",
    "        # 8维中心→d维中心\n",
    "        cluster_centers_8d = self.cluster_centers_8d[non_noise_labels]\n",
    "        cluster_centers_d = self.cluster_projection(cluster_centers_8d)\n",
    "        \n",
    "        # 填充结果（噪声物品返回零向量）\n",
    "        batch_size = item_ids.size(0)\n",
    "        centers_d = torch.zeros(batch_size, self.hidden_size, device=self.device)\n",
    "        centers_d[non_noise_indices] = cluster_centers_d\n",
    "        return centers_d, non_noise_mask\n",
    "\n",
    "    def calculate_cluster_loss(self, item_ids, item_embeddings):\n",
    "        \"\"\"\n",
    "        兼容逻辑：根据use_fuzzy开关，返回传统聚类损失或模糊-密度约束损失\n",
    "        item_ids: 有效物品ID（1-D Tensor，如[102, 345, ...]）\n",
    "        item_embeddings: 物品嵌入（shape: [valid_num, hidden_size]）\n",
    "        \"\"\"\n",
    "        if item_ids.numel() == 0:  # 无有效物品，损失为0\n",
    "            return torch.tensor(0.0, device=self.device)\n",
    "\n",
    "         # 新增打印：确认use_fuzzy状态和当前执行的分支\n",
    "        print(f\"[ClusterHandler] use_fuzzy={self.use_fuzzy} | 执行{'模糊损失' if self.use_fuzzy else '传统聚类损失'}\")\n",
    "        \n",
    "        # 开关控制：启用模糊损失则计算模糊约束，否则计算传统聚类损失\n",
    "        if self.use_fuzzy:\n",
    "            return self._calculate_fuzzy_loss(item_ids, item_embeddings)\n",
    "        else:\n",
    "            return self._calculate_traditional_cluster_loss(item_ids, item_embeddings)\n",
    "\n",
    "    def _calculate_traditional_cluster_loss(self, item_ids, item_embeddings):\n",
    "        \"\"\"原有逻辑：计算传统聚类损失（非噪声物品的L2损失）\"\"\"\n",
    "        centers_d, non_noise_mask = self.get_cluster_center(item_ids)\n",
    "        if non_noise_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=self.device)\n",
    "        \n",
    "        # 非噪声物品的L2损失\n",
    "        non_noise_emb = item_embeddings[non_noise_mask]\n",
    "        non_noise_centers = centers_d[non_noise_mask]\n",
    "        return torch.mean(torch.norm(non_noise_emb - non_noise_centers, p=2, dim=1)**2)\n",
    "\n",
    "    def _calculate_fuzzy_loss(self, item_ids, item_embeddings):\n",
    "        \"\"\"\n",
    "        新增：计算模糊-密度约束损失（动态模糊原型+MSE）\n",
    "        对应文档中“模糊隶属度向量→动态原型→MSE约束”逻辑\n",
    "        \"\"\"\n",
    "        # 1. 过滤无效物品ID（避免索引超出fuzzy_U范围）\n",
    "        valid_mask = item_ids < self.fuzzy_U.shape[0]  # 物品ID不能大于模糊隶属度向量的长度\n",
    "        valid_ids = item_ids[valid_mask]\n",
    "        valid_emb = item_embeddings[valid_mask]\n",
    "        \n",
    "        if valid_ids.numel() == 0:  # 无有效物品，损失为0\n",
    "            return torch.tensor(0.0, device=self.device)\n",
    "        \n",
    "        # 2. 索引当前物品的模糊隶属度（shape: [valid_num, num_fuzzy_clusters]）\n",
    "        batch_fuzzy_U = self.fuzzy_U[valid_ids]\n",
    "        \n",
    "        # 3. 计算动态模糊原型（文档核心：Prototype_i = Σ(μ_ij^m * cluster_center_j)）\n",
    "        fuzzy_weights = batch_fuzzy_U ** self.fuzzy_m  # 模糊权重（μ^m，增强隶属度差异）\n",
    "        # 加权求和：[valid_num, C, 1] × [C, d] → [valid_num, d]\n",
    "        prototypes = torch.matmul(\n",
    "            fuzzy_weights.unsqueeze(1),  # [valid_num, 1, C]\n",
    "            self.hdbscan_cluster_centers.unsqueeze(0)  # [1, C, d]\n",
    "        ).squeeze(1)  # [valid_num, d]\n",
    "        \n",
    "        # 4. MSE损失（物品嵌入与动态原型的平滑约束，文档中“无缝约束”）\n",
    "        fuzzy_loss = F.mse_loss(valid_emb, prototypes)\n",
    "        return fuzzy_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9003b2c7-12f9-410c-8e1e-262d3e085686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here put the import lib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.DualLLMSRS import DualLLMSASRec, DualLLMGRU4Rec, DualLLMBert4Rec\n",
    "from models.utils import Contrastive_Loss2, ClusterHandler  # 确保导入修改后的ClusterHandler\n",
    "\n",
    "\n",
    "class LLMESR_SASRec(DualLLMSASRec):\n",
    "\n",
    "    def __init__(self, user_num, item_num, device, args):\n",
    "\n",
    "        super().__init__(user_num, item_num, device, args)\n",
    "        self.alpha = args.alpha\n",
    "        self.user_sim_func = args.user_sim_func\n",
    "        self.item_reg = args.item_reg\n",
    "        self.gamma = args.gamma  # 聚类约束强度\n",
    "\n",
    "        # ---------------------- 关键修改：向ClusterHandler传递use_fuzzy参数 ----------------------\n",
    "        self.cluster_handler = ClusterHandler(\n",
    "            dataset=args.dataset,          # 数据集名称（如\"fashion\"）\n",
    "            hidden_size=args.hidden_size,  # 嵌入维度（64 for Fashion）\n",
    "            device=device,\n",
    "            use_fuzzy=args.use_fuzzy       # 新增：传递模糊约束开关（从命令行参数获取）\n",
    "        )\n",
    "\n",
    "        if self.user_sim_func == \"cl\":\n",
    "            self.align = Contrastive_Loss2()\n",
    "        elif self.user_sim_func == \"kd\":\n",
    "            self.align = nn.MSELoss()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        self.projector1 = nn.Linear(2*args.hidden_size, 2*args.hidden_size)\n",
    "        self.projector2 = nn.Linear(2*args.hidden_size, 2*args.hidden_size)\n",
    "\n",
    "        if self.item_reg:\n",
    "            self.beta = args.beta\n",
    "            self.reg = Contrastive_Loss2()\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "                seq, \n",
    "                pos, \n",
    "                neg, \n",
    "                positions,\n",
    "                **kwargs):\n",
    "        \n",
    "        loss = super().forward(seq, pos, neg, positions, **kwargs)  # 原有损失\n",
    "        \n",
    "        log_feats = self.log2feats(seq, positions)[:, -1, :]\n",
    "        sim_seq, sim_positions = kwargs[\"sim_seq\"].view(-1, seq.shape[1]), kwargs[\"sim_positions\"].view(-1, seq.shape[1])\n",
    "        sim_num = kwargs[\"sim_seq\"].shape[1]\n",
    "        sim_log_feats = self.log2feats(sim_seq, sim_positions)[:, -1, :]    # (bs*sim_num, hidden_size)\n",
    "        sim_log_feats = sim_log_feats.detach().view(seq.shape[0], sim_num, -1)  # (bs, sim_num, hidden_size)\n",
    "        sim_log_feats = torch.mean(sim_log_feats, dim=1)\n",
    "\n",
    "        if self.user_sim_func == \"cl\":\n",
    "            align_loss = self.align(log_feats, sim_log_feats)\n",
    "        elif self.user_sim_func == \"kd\":\n",
    "            align_loss = self.align(log_feats, sim_log_feats)\n",
    "\n",
    "        if self.item_reg:\n",
    "            unfold_item_id = torch.masked_select(seq, seq>0)\n",
    "            llm_item_emb = self.adapter(self.llm_item_emb(unfold_item_id))\n",
    "            id_item_emb = self.id_item_emb(unfold_item_id)\n",
    "            reg_loss = self.reg(llm_item_emb, id_item_emb)\n",
    "            loss += self.beta * reg_loss\n",
    "\n",
    "        # ---------------------- 损失计算逻辑不变（ClusterHandler内部已适配） ----------------------\n",
    "        # 计算聚类约束损失（根据use_fuzzy自动切换传统/模糊损失）\n",
    "        item_ids = seq[seq > 0]  # 有效物品ID\n",
    "        item_embeddings = self.id_item_emb(item_ids)  # 获取物品嵌入\n",
    "        cluster_loss = self.cluster_handler.calculate_cluster_loss(item_ids, item_embeddings)\n",
    "        loss += self.gamma * cluster_loss\n",
    "\n",
    "        loss += self.alpha * align_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "# ---------------------- 以下为LLMESR_GRU4Rec和LLMESR_Bert4Rec的修改（类似） ----------------------\n",
    "class LLMESR_GRU4Rec(DualLLMGRU4Rec):\n",
    "\n",
    "    def __init__(self, user_num, item_num, device, args):\n",
    "\n",
    "        super().__init__(user_num, item_num, device, args)\n",
    "        self.alpha = args.alpha\n",
    "        self.user_sim_func = args.user_sim_func\n",
    "        self.item_reg = args.item_reg\n",
    "        self.gamma = args.gamma  # 聚类约束强度\n",
    "\n",
    "        # 关键修改：传递use_fuzzy参数\n",
    "        self.cluster_handler = ClusterHandler(\n",
    "            dataset=args.dataset,\n",
    "            hidden_size=args.hidden_size,\n",
    "            device=device,\n",
    "            use_fuzzy=args.use_fuzzy  # 新增\n",
    "        )\n",
    "\n",
    "        # 其余初始化逻辑不变...\n",
    "        if self.user_sim_func == \"cl\":\n",
    "            self.align = Contrastive_Loss2()\n",
    "        elif self.user_sim_func == \"kd\":\n",
    "            self.align = nn.MSELoss()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        self.projector1 = nn.Linear(2*args.hidden_size, 2*args.hidden_size)\n",
    "        self.projector2 = nn.Linear(2*args.hidden_size, 2*args.hidden_size)\n",
    "\n",
    "        if self.item_reg:\n",
    "            self.beta = args.beta\n",
    "            self.reg = Contrastive_Loss2()\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "                seq, \n",
    "                pos, \n",
    "                neg, \n",
    "                positions,\n",
    "                **kwargs):\n",
    "        \n",
    "        # 原有forward逻辑不变...\n",
    "        loss = super().forward(seq, pos, neg, positions, **kwargs)\n",
    "        \n",
    "        log_feats = self.log2feats(seq)[:, -1, :]\n",
    "        sim_seq, sim_positions = kwargs[\"sim_seq\"].view(-1, seq.shape[1]), kwargs[\"sim_positions\"].view(-1, seq.shape[1])\n",
    "        sim_num = kwargs[\"sim_seq\"].shape[1]\n",
    "        sim_log_feats = self.log2feats(sim_seq)[:, -1, :]    \n",
    "        sim_log_feats = sim_log_feats.detach().view(seq.shape[0], sim_num, -1)\n",
    "        sim_log_feats = torch.mean(sim_log_feats, dim=1)\n",
    "\n",
    "        if self.user_sim_func == \"cl\":\n",
    "            align_loss = self.align(log_feats, sim_log_feats)\n",
    "        elif self.user_sim_func == \"kd\":\n",
    "            align_loss = self.align(log_feats, sim_log_feats)\n",
    "\n",
    "        if self.item_reg:\n",
    "            unfold_item_id = torch.masked_select(seq, seq>0)\n",
    "            llm_item_emb = self.adapter(self.llm_item_emb(unfold_item_id))\n",
    "            id_item_emb = self.id_item_emb(unfold_item_id)\n",
    "            reg_loss = self.reg(llm_item_emb, id_item_emb)\n",
    "            loss += self.beta * reg_loss\n",
    "\n",
    "        # 聚类损失计算（自动适配）\n",
    "        item_ids = seq[seq > 0]\n",
    "        item_embeddings = self.id_item_emb(item_ids)\n",
    "        cluster_loss = self.cluster_handler.calculate_cluster_loss(item_ids, item_embeddings)\n",
    "        loss += self.gamma * cluster_loss\n",
    "\n",
    "        loss += self.alpha * align_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class LLMESR_Bert4Rec(DualLLMBert4Rec):\n",
    "\n",
    "    def __init__(self, user_num, item_num, device, args):\n",
    "\n",
    "        super().__init__(user_num, item_num, device, args)\n",
    "        self.alpha = args.alpha\n",
    "        self.user_sim_func = args.user_sim_func\n",
    "        self.item_reg = args.item_reg\n",
    "        self.gamma = args.gamma  # 聚类约束强度超参数\n",
    "\n",
    "        # 关键修改：传递use_fuzzy参数\n",
    "        self.cluster_handler = ClusterHandler(\n",
    "            dataset=args.dataset,\n",
    "            hidden_size=args.hidden_size,\n",
    "            device=device,\n",
    "            use_fuzzy=args.use_fuzzy  # 新增\n",
    "        )\n",
    "\n",
    "        # 其余初始化逻辑不变...\n",
    "        if self.user_sim_func == \"cl\":\n",
    "            self.align = Contrastive_Loss2()\n",
    "        elif self.user_sim_func == \"kd\":\n",
    "            self.align = nn.MSELoss()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        self.projector1 = nn.Linear(2*args.hidden_size, 2*args.hidden_size)\n",
    "        self.projector2 = nn.Linear(2*args.hidden_size, 2*args.hidden_size)\n",
    "\n",
    "        if self.item_reg:\n",
    "            self.reg = Contrastive_Loss2()\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "                seq, \n",
    "                pos, \n",
    "                neg, \n",
    "                positions,\n",
    "                **kwargs):\n",
    "        \n",
    "        loss = super().forward(seq, pos, neg, positions, **kwargs)\n",
    "        \n",
    "        log_feats = self.log2feats(seq, positions)[:, -1, :]\n",
    "        sim_seq, sim_positions = kwargs[\"sim_seq\"].view(-1, seq.shape[1]), kwargs[\"sim_positions\"].view(-1, seq.shape[1])\n",
    "        sim_num = kwargs[\"sim_seq\"].shape[1]\n",
    "        sim_log_feats = self.log2feats(sim_seq, sim_positions)[:, -1, :]\n",
    "        sim_log_feats = sim_log_feats.detach().view(seq.shape[0], sim_num, -1)\n",
    "        sim_log_feats = torch.mean(sim_log_feats, dim=1)\n",
    "\n",
    "        if self.user_sim_func == \"cl\":\n",
    "            align_loss = self.align(log_feats, sim_log_feats)\n",
    "        elif self.user_sim_func == \"kd\":\n",
    "            align_loss = self.align(log_feats, sim_log_feats)\n",
    "\n",
    "        # 聚类损失计算（自动适配）\n",
    "        cluster_loss = self.calculate_cluster_loss(seq)\n",
    "\n",
    "        # 整合所有损失\n",
    "        loss += self.gamma * cluster_loss  # 聚类约束损失\n",
    "        loss += self.alpha * align_loss\n",
    "\n",
    "        return loss\n",
    "        \n",
    "    def calculate_cluster_loss(self, seq):\n",
    "        # 原有过滤逻辑不变...\n",
    "        valid_mask = (seq > 0) & (seq != self.mask_token)        \n",
    "        item_ids   = seq[valid_mask]                             \n",
    "        if item_ids.numel() == 0:                                \n",
    "            return torch.tensor(0.0, device=seq.device)\n",
    "        \n",
    "        max_id_in_cluster = self.cluster_handler.item_cluster.size(0) - 1\n",
    "        item_ids = item_ids[item_ids <= max_id_in_cluster]\n",
    "\n",
    "        if item_ids.numel() == 0:                                \n",
    "            return torch.tensor(0.0, device=seq.device)\n",
    "        \n",
    "        # 调用修改后的cluster_handler计算损失（自动切换传统/模糊损失）\n",
    "        item_embeddings = self.id_item_emb(item_ids)\n",
    "        cluster_loss    = self.cluster_handler.calculate_cluster_loss(item_ids, item_embeddings)\n",
    "        return cluster_loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
