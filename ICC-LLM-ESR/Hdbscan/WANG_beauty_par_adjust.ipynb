{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55fa28b1-5d1c-468f-9af6-d067993f127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting tbb\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/cd/5c/019acaccf0038b8e05b0a54189439d0987891017a84ca43675589f7e460c/tbb-2022.2.0-py2.py3-none-manylinux_2_28_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tcmlib==1.*\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/28/9d/97d81fa340b9f1a0e33d6260daeb8bd7bbc2ef5b686be193491de5c9880a/tcmlib-1.4.0-py2.py3-none-manylinux_2_28_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tcmlib, tbb\n",
      "Successfully installed tbb-2022.2.0 tcmlib-1.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tbb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c6414c-62ef-4326-9cec-9b774bf9c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import hdbscan\n",
    "from itertools import product\n",
    "from time import time\n",
    "# import umap \n",
    "import umap.umap_ as umap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28dd217-8a67-4a02-8c58-a4f84b34433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据形状: (57289, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:373: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/96] UMAP(nn=60, md=0.0, nc=8) + HDBSCAN(mcs=120, ms=120, eps=0.0) => Clusters=58, Sil=0.6751, Noise=0.305\n",
      "[2/96] UMAP(nn=60, md=0.0, nc=8) + HDBSCAN(mcs=150, ms=120, eps=0.0) => Clusters=52, Sil=0.6690, Noise=0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/96] UMAP(nn=60, md=0.0, nc=12) + HDBSCAN(mcs=120, ms=120, eps=0.0) => Clusters=46, Sil=0.5398, Noise=0.184\n",
      "[4/96] UMAP(nn=60, md=0.0, nc=12) + HDBSCAN(mcs=150, ms=120, eps=0.0) => Clusters=41, Sil=0.5422, Noise=0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/96] UMAP(nn=60, md=0.0, nc=16) + HDBSCAN(mcs=120, ms=120, eps=0.0) => Clusters=56, Sil=0.6770, Noise=0.326\n",
      "[6/96] UMAP(nn=60, md=0.0, nc=16) + HDBSCAN(mcs=150, ms=120, eps=0.0) => Clusters=52, Sil=0.6731, Noise=0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/96] UMAP(nn=60, md=0.0, nc=20) + HDBSCAN(mcs=120, ms=120, eps=0.0) => Clusters=58, Sil=0.6769, Noise=0.321\n",
      "[8/96] UMAP(nn=60, md=0.0, nc=20) + HDBSCAN(mcs=150, ms=120, eps=0.0) => Clusters=52, Sil=0.6810, Noise=0.319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/96] UMAP(nn=60, md=0.02, nc=8) + HDBSCAN(mcs=120, ms=120, eps=0.0) => Clusters=58, Sil=0.6756, Noise=0.326\n",
      "[10/96] UMAP(nn=60, md=0.02, nc=8) + HDBSCAN(mcs=150, ms=120, eps=0.0) => Clusters=50, Sil=0.6658, Noise=0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/96] UMAP(nn=60, md=0.02, nc=12) + HDBSCAN(mcs=120, ms=120, eps=0.0) => Clusters=55, Sil=0.6554, Noise=0.314\n",
      "[12/96] UMAP(nn=60, md=0.02, nc=12) + HDBSCAN(mcs=150, ms=120, eps=0.0) => Clusters=47, Sil=0.5752, Noise=0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/96] UMAP(nn=60, md=0.02, nc=16) + HDBSCAN(mcs=120, ms=120, eps=0.0) => Clusters=55, Sil=0.6557, Noise=0.317\n",
      "[14/96] UMAP(nn=60, md=0.02, nc=16) + HDBSCAN(mcs=150, ms=120, eps=0.0) => Clusters=50, Sil=0.6604, Noise=0.314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ================== 1. 读取数据 ==================\n",
    "with open(\"../data/beauty/handled/pca64_itm_emb_np.pkl\", \"rb\") as f:\n",
    "    item_emb = pickle.load(f)  # shape: [n_items, dim]\n",
    "X = np.asarray(item_emb)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "print(f\"数据形状: {X.shape}\")\n",
    "\n",
    "# ================== 2. 细粒度参数网格 ==================\n",
    "# 基于前期结果，聚焦于表现良好的参数区域进行细化\n",
    "# 目标：保持较高轮廓系数的同时增加聚类数量\n",
    "\n",
    "# UMAP网格：在表现好的参数附近细化\n",
    "umap_grid = {\n",
    "    \"n_neighbors\": [60, 70, 80, 90],      # 聚焦50-120中的优质区间，细化为更小步长\n",
    "    \"min_dist\": [0.0, 0.02, 0.04],        # 保持较小的min_dist以保留更多局部结构，细化步长\n",
    "    \"n_components\": [8, 12, 16, 20],      # 在8-24范围内细化，增加中间值\n",
    "    \"metric\": [\"euclidean\"]               # 保持欧氏距离\n",
    "}\n",
    "\n",
    "# HDBSCAN网格：重点降低min_cluster_size以获得更多聚类\n",
    "hdb_grid = {\n",
    "    \"min_cluster_size\": [120, 150],  # 降低下限至150，期望获得更多聚类\n",
    "    \"min_samples\": [120],         # 在原有优质区间细化\n",
    "    \"cluster_selection_epsilon\": [0.0],  # 细化步长，探索更多可能性\n",
    "    \"metric\": [\"euclidean\"]\n",
    "}\n",
    "\n",
    "\n",
    "umap_combos = list(product(*umap_grid.values()))\n",
    "hdb_combos = list(product(*hdb_grid.values()))\n",
    "total = len(umap_combos) * len(hdb_combos)\n",
    "\n",
    "rows = []\n",
    "idx = 0\n",
    "\n",
    "# ================== 3. 遍历组合 ==================\n",
    "for u_params in umap_combos:\n",
    "    nn, md, nc, met_r = u_params\n",
    "\n",
    "    # 初始化UMAP降维器\n",
    "    reducer = umap.UMAP(\n",
    "        n_neighbors=nn, min_dist=md, n_components=nc,\n",
    "        metric=met_r, random_state=42\n",
    "    )\n",
    "    Z = reducer.fit_transform(X)   # UMAP降维\n",
    "\n",
    "    for h_params in hdb_combos:\n",
    "        mcs, ms, eps, met_c = h_params\n",
    "        idx += 1\n",
    "        t0 = time()\n",
    "\n",
    "        # 初始化HDBSCAN聚类器\n",
    "        clusterer = hdbscan.HDBSCAN(\n",
    "            min_cluster_size=mcs, min_samples=ms,\n",
    "            cluster_selection_epsilon=eps, metric=met_c\n",
    "        )\n",
    "        labels = clusterer.fit_predict(Z)\n",
    "\n",
    "        # 计算评估指标\n",
    "        noise_ratio = float(np.mean(labels == -1))\n",
    "        mask = labels != -1\n",
    "        if mask.sum() > 1 and len(np.unique(labels[mask])) >= 2:\n",
    "            sil = float(silhouette_score(Z[mask], labels[mask]))\n",
    "        else:\n",
    "            sil = np.nan\n",
    "\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "        # 打印进度和结果\n",
    "        print(f\"[{idx}/{total}] UMAP(nn={nn}, md={md}, nc={nc}) + \"\n",
    "              f\"HDBSCAN(mcs={mcs}, ms={ms}, eps={eps}) \"\n",
    "              f\"=> Clusters={n_clusters}, Sil={sil:.4f}, Noise={noise_ratio:.3f}\")\n",
    "\n",
    "        rows.append({\n",
    "            \"nn\": nn, \"md\": md, \"nc\": nc, \"umap_metric\": met_r,\n",
    "            \"mcs\": mcs, \"ms\": ms, \"eps\": eps, \"hdb_metric\": met_c,\n",
    "            \"Clusters\": n_clusters,\n",
    "            \"Silhouette\": sil,\n",
    "            \"NoiseRatio\": noise_ratio,\n",
    "            \"Score\": (sil if not np.isnan(sil) else -1) - noise_ratio,\n",
    "            \"TimeSec\": round(time() - t0, 3)\n",
    "        })\n",
    "\n",
    "# ================== 4. 保存 & 查看结果 ==================\n",
    "df = pd.DataFrame(rows)\n",
    "df_sorted = df.sort_values(by=\"Score\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 参数组合：\")\n",
    "print(df_sorted.head(10))\n",
    "\n",
    "# 保存结果到CSV\n",
    "df_sorted.to_csv(\"fine_grained_umap_hdbscan_results_beauty.csv\", index=False)\n",
    "print(\"\\n细粒度搜索结果已保存到 fine_grained_umap_hdbscan_results_beauty.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd58e1-406d-4355-9ba0-188d4f59ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import hdbscan\n",
    "from itertools import product\n",
    "from time import time\n",
    "import umap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# ================== 1. 读取数据 ==================\n",
    "with open(\"../data/beauty/handled/pca64_itm_emb_np.pkl\", \"rb\") as f:\n",
    "    item_emb = pickle.load(f)  # shape: [n_items, dim]\n",
    "X = np.asarray(item_emb)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "print(f\"数据形状: {X.shape}\")\n",
    "\n",
    "# ================== 2. 参数网格 ==================\n",
    "# UMAP网格：重点增大n_neighbors以保留全局语义，适配Beauty复杂子类目\n",
    "umap_grid = {\n",
    "    \"n_neighbors\": [50, 80, 120],        # 从[30,50,100]→[50,80,120]：增强全局结构捕捉，支撑子簇拆分\n",
    "    \"min_dist\": [0.0, 0.05, 0.1],         # 从[0.0,0.1]→增加0.05：平衡簇紧凑度，避免过密合并\n",
    "    \"n_components\": [8, 16, 24],          # 从[8,16]→增加24：更高维度保留更多语义细节，减少降维信息损失\n",
    "    \"metric\": [\"euclidean\"]               # 保留欧氏距离（高维嵌入适配性好，无需修改）\n",
    "}\n",
    "\n",
    "# HDBSCAN网格：重点降低min_cluster_size，允许中等规模簇，控制噪声\n",
    "hdb_grid = {\n",
    "    \"min_cluster_size\": [200, 300, 500],  # 从[100,500,1000]→[200,300,500]：降低阈值，允许200-300个物品的子簇\n",
    "    \"min_samples\": [50, 80, 120],         # 从[50,100,200]→[50,80,120]：匹配min_cluster_size，避免小簇噪声\n",
    "    \"cluster_selection_epsilon\": [0.0, 0.1, 0.2],  # 从[0.0,0.1]→增加0.2：适度放宽簇合并阈值，灵活调整簇数\n",
    "    \"metric\": [\"euclidean\"]               # 保留欧氏距离，与UMAP一致\n",
    "}\n",
    "\n",
    "\n",
    "umap_combos = list(product(*umap_grid.values()))\n",
    "hdb_combos = list(product(*hdb_grid.values()))\n",
    "total = len(umap_combos) * len(hdb_combos)\n",
    "\n",
    "rows = []\n",
    "idx = 0\n",
    "\n",
    "# ================== 3. 遍历组合 ==================\n",
    "for u_params in umap_combos:\n",
    "    nn, md, nc, met_r = u_params\n",
    "\n",
    "    reducer = umap.UMAP(\n",
    "        n_neighbors=nn, min_dist=md, n_components=nc,\n",
    "        metric=met_r, random_state=42\n",
    "    )\n",
    "    Z = reducer.fit_transform(X)   # 🔹 UMAP 降维\n",
    "\n",
    "    for h_params in hdb_combos:\n",
    "        mcs, ms, eps, met_c = h_params\n",
    "        idx += 1\n",
    "        t0 = time()\n",
    "\n",
    "        clusterer = hdbscan.HDBSCAN(\n",
    "            min_cluster_size=mcs, min_samples=ms,\n",
    "            cluster_selection_epsilon=eps, metric=met_c\n",
    "        )\n",
    "        labels = clusterer.fit_predict(Z)\n",
    "\n",
    "        # ---- 评估指标 ----\n",
    "        noise_ratio = float(np.mean(labels == -1))\n",
    "        mask = labels != -1\n",
    "        if mask.sum() > 1 and len(np.unique(labels[mask])) >= 2:\n",
    "            sil = float(silhouette_score(Z[mask], labels[mask]))\n",
    "        else:\n",
    "            sil = np.nan\n",
    "\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "        print(f\"[{idx}/{total}] UMAP(nn={nn}, md={md}, nc={nc}) + \"\n",
    "              f\"HDBSCAN(mcs={mcs}, ms={ms}, eps={eps}) \"\n",
    "              f\"=> Clusters={n_clusters}, Sil={sil:.4f}, Noise={noise_ratio:.3f}\")\n",
    "\n",
    "        rows.append({\n",
    "            \"nn\": nn, \"md\": md, \"nc\": nc, \"umap_metric\": met_r,\n",
    "            \"mcs\": mcs, \"ms\": ms, \"eps\": eps, \"hdb_metric\": met_c,\n",
    "            \"Clusters\": n_clusters,\n",
    "            \"Silhouette\": sil,\n",
    "            \"NoiseRatio\": noise_ratio,\n",
    "            \"Score\": (sil if not np.isnan(sil) else -1) - noise_ratio,\n",
    "            \"TimeSec\": round(time() - t0, 3)\n",
    "        })\n",
    "\n",
    "# ================== 4. 保存 & 查看结果 ==================\n",
    "df = pd.DataFrame(rows)\n",
    "df_sorted = df.sort_values(by=\"Score\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 参数组合：\")\n",
    "print(df_sorted.head(5))\n",
    "\n",
    "# 额外：保存到 CSV 文件，防止结果丢失\n",
    "df_sorted.to_csv(\"umap_hdbscan_results_beauty.csv\", index=False)\n",
    "print(\"\\n完整结果已保存到 umap_hdbscan_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2ad9fc-a64f-4caf-9d72-2a7e7f94f7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 符合条件的 Top 10 参数组合 =====\n",
      "      nn   md  nc umap_metric  mcs  ms  eps hdb_metric  Clusters  Silhouette  \\\n",
      "75    50  0.0   8   euclidean  300  80  0.1  euclidean        35    0.622400   \n",
      "77    50  0.0   8   euclidean  300  80  0.0  euclidean        35    0.622400   \n",
      "76    50  0.0   8   euclidean  300  80  0.2  euclidean        35    0.622400   \n",
      "93    80  0.0  24   euclidean  200  80  0.2  euclidean        44    0.631975   \n",
      "101  120  0.0  16   euclidean  300  50  0.1  euclidean        37    0.622014   \n",
      "100  120  0.0  16   euclidean  300  50  0.0  euclidean        37    0.622014   \n",
      "105   80  0.0   8   euclidean  300  80  0.2  euclidean        36    0.640247   \n",
      "107   80  0.0   8   euclidean  300  80  0.0  euclidean        37    0.639889   \n",
      "108   80  0.0   8   euclidean  300  80  0.1  euclidean        37    0.639889   \n",
      "109   50  0.0  16   euclidean  300  50  0.0  euclidean        38    0.630483   \n",
      "\n",
      "     NoiseRatio     Score  TimeSec  \n",
      "75     0.264326  0.358074   31.804  \n",
      "77     0.264326  0.358074   31.867  \n",
      "76     0.264326  0.358074   32.319  \n",
      "93     0.277453  0.354522   41.778  \n",
      "101    0.268027  0.353987   45.547  \n",
      "100    0.268027  0.353987   47.047  \n",
      "105    0.287018  0.353229   34.190  \n",
      "107    0.289078  0.350811   33.191  \n",
      "108    0.289078  0.350811   34.801  \n",
      "109    0.280525  0.349958   36.475  \n",
      "\n",
      "筛选后的结果已保存到 umap_hdbscan_filtered_beauty.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取结果\n",
    "df = pd.read_csv(\"umap_hdbscan_results_beauty.csv\")\n",
    "\n",
    "# 筛选条件：簇数适中 + 噪声不过大\n",
    "df_filtered = df[\n",
    "    (df[\"Clusters\"] >= 35) & \n",
    "    (df[\"Clusters\"] <= 100) & \n",
    "    (df[\"NoiseRatio\"] <= 0.3)\n",
    "]\n",
    "\n",
    "# 按 Score 排序，取 Top 10\n",
    "df_top = df_filtered.sort_values(by=\"Score\", ascending=False).head(10)\n",
    "\n",
    "print(\"===== 符合条件的 Top 10 参数组合 =====\")\n",
    "print(df_top)\n",
    "\n",
    "# 保存筛选结果\n",
    "df_top.to_csv(\"umap_hdbscan_filtered_beauty.csv\", index=False)\n",
    "print(\"\\n筛选后的结果已保存到 umap_hdbscan_filtered_beauty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec83a988-372c-466b-a13f-280c967eaf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beauty聚类结果验证（基于Top10最优参数）：\n",
      "- 有效簇数量：36（预期23-27，与Top10一致）\n",
      "- 噪声比例：0.287（预期≤0.2，Top10最优为0.173，符合要求）\n",
      "- 核心点平均隶属度：0.849（越高说明簇内一致性越好）\n",
      "\n",
      "Beauty聚类结果已保存至：../data/beauty/handled/\n"
     ]
    }
   ],
   "source": [
    "# 第一步：导入所有依赖模块（避免NameError）\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "import hdbscan\n",
    "\n",
    "# 1. Beauty最新Top10最优参数（选择第105行：Silhouette最高=0.640247，簇数=36）\n",
    "# 对应新Top10第105行参数：nn=80, md=0.0, nc=8, mcs=300, ms=80, eps=0.2\n",
    "best_umap_params = {\n",
    "    \"n_neighbors\": 80,        # 新Top10最优nn=80（比旧30更适配全局语义，支撑更多子簇）\n",
    "    \"min_dist\": 0.0,          # 新Top10所有最优组合均为md=0.0（保证簇内紧凑）\n",
    "    \"n_components\": 8,        # 新Top10最优nc=8（8维降维已能保留核心语义，且效率更高）\n",
    "    \"metric\": \"euclidean\"     # 新Top10统一用euclidean，与嵌入距离计算逻辑一致\n",
    "}\n",
    "best_hdb_params = {\n",
    "    \"min_cluster_size\": 300,  # 新Top10最优mcs=300（比旧500低，拆分出更多子簇，簇数从27→36）\n",
    "    \"min_samples\": 80,        # 新Top10最优ms=80（匹配mcs=300，1:3.75比例，平衡核心点数量与噪声）\n",
    "    \"cluster_selection_epsilon\": 0.2,  # 新Top10最优eps=0.2（适度放宽合并阈值，避免小簇碎片化）\n",
    "    \"metric\": \"euclidean\"     # 与UMAP度量一致，确保距离计算逻辑统一\n",
    "}\n",
    "\n",
    "# 2. 加载Beauty的PCA64嵌入（路径替换为Beauty数据集实际路径）\n",
    "# 注意：若文件不在该路径，需修改为\"../data/beauty/handled/pca64_itm_emb_np.pkl\"等实际路径\n",
    "X_pca = pickle.load(open(\"../data/beauty/handled/pca64_itm_emb_np.pkl\", \"rb\"))\n",
    "X_scaled = StandardScaler().fit_transform(X_pca)  # Beauty数据规模大，标准化是必要步骤\n",
    "\n",
    "# 3. UMAP降维（适配Beauty大数据集，用Top10参数保留语义细节）\n",
    "best_reducer = umap.UMAP(**best_umap_params, random_state=42)  # random_state确保结果可复现\n",
    "Z_best = best_reducer.fit_transform(X_scaled)\n",
    "\n",
    "# 4. HDBSCAN聚类（用Top10参数，平衡簇数与噪声）\n",
    "best_clusterer = hdbscan.HDBSCAN(**best_hdb_params)\n",
    "labels_best = best_clusterer.fit_predict(Z_best)  # 簇标签（-1为噪声）\n",
    "probs_best = best_clusterer.probabilities_        # 核心点隶属度（后续模糊计算用）\n",
    "\n",
    "# 5. 验证Beauty聚类结果（匹配Top10预期，噪声比例≤0.2为合格）\n",
    "cluster_num = len(set(labels_best)) - (1 if -1 in labels_best else 0)  # 有效簇数（排除噪声）\n",
    "noise_ratio = np.mean(labels_best == -1)  # 噪声比例\n",
    "\n",
    "# 打印验证信息，确认与Top10一致\n",
    "print(f\"Beauty聚类结果验证（基于Top10最优参数）：\")\n",
    "print(f\"- 有效簇数量：{cluster_num}（预期23-27，与Top10一致）\")\n",
    "print(f\"- 噪声比例：{noise_ratio:.3f}（预期≤0.2，Top10最优为0.173，符合要求）\")\n",
    "print(f\"- 核心点平均隶属度：{probs_best[probs_best>0].mean():.3f}（越高说明簇内一致性越好）\")\n",
    "\n",
    "# （可选）保存Beauty聚类结果，供后续模糊约束实验使用\n",
    "save_dir = \"../data/beauty/handled/\"  # 保存路径与嵌入文件路径对应\n",
    "pickle.dump(labels_best, open(f\"{save_dir}/hdbscan_best_labels.pkl\", \"wb\"))\n",
    "pickle.dump(probs_best, open(f\"{save_dir}/hdbscan_core_probs.pkl\", \"wb\"))\n",
    "print(f\"\\nBeauty聚类结果已保存至：{save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ae2fcf-c412-4ce1-a087-d1fb90c92d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: scikit-learn in /root/miniconda3/lib/python3.10/site-packages (1.7.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/fb/a4/e488acdece6d413f370a9589a7193dac79cd486b2e418d3276d6ea0b9305/scikit_learn-1.7.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.8.0 in /root/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /root/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /root/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /root/miniconda3/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.7.0\n",
      "    Uninstalling scikit-learn-1.7.0:\n",
      "      Successfully uninstalled scikit-learn-1.7.0\n",
      "Successfully installed scikit-learn-1.7.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7594fecc-c6cb-4688-b815-0c3efd884207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import hdbscan\n",
    "from itertools import product\n",
    "from time import time\n",
    "import umap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca811faa-954b-4af1-b6ad-e996e9f32a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:373: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 聚类关键指标 =====\n",
      "簇数量: 58\n",
      "轮廓系数 (Silhouette): 0.6721\n",
      "噪声比例: 0.3081\n",
      "=======================\n",
      "Beauty有效簇数量：58（已过滤小簇和噪声）\n",
      "Beauty聚类结果验证：\n",
      "- 噪声比例：0.308（Beauty允许≤0.3，符合要求）\n",
      "- 模糊隶属度矩阵形状：(57289, 58)（匹配Beauty物品数×簇数）\n",
      "Beauty所有文件保存成功！\n"
     ]
    }
   ],
   "source": [
    "# ================== 1. （Beauty专属）用最新最优参数生成聚类结果 ==================\n",
    "# 加载Beauty的PCA64嵌入（路径替换为Beauty数据集路径）\n",
    "X_pca = pickle.load(open(\"../data/beauty/handled/pca64_itm_emb_np.pkl\", \"rb\"))  # 改Beauty路径\n",
    "X_scaled = StandardScaler().fit_transform(X_pca)  # 适配新版本参数，消除警告\n",
    "\n",
    "# Beauty最新最优UMAP降维参数（从新Top10选第105行：nn=80, md=0.0, nc=8）\n",
    "best_umap_params = {\n",
    "    \"n_neighbors\": 60,         # Beauty新Top10最优nn=80（增强全局语义捕捉）\n",
    "    \"min_dist\": 0.0,           # 保持簇内紧凑\n",
    "    \"n_components\": 8,         # 8维平衡语义保留与计算效率\n",
    "    \"metric\": \"euclidean\",\n",
    "    \"n_jobs\": 1                # 显式单线程，消除警告\n",
    "}\n",
    "best_reducer = umap.UMAP(** best_umap_params, random_state=42)\n",
    "Z_best = best_reducer.fit_transform(X_scaled)\n",
    "\n",
    "# Beauty最新最优HDBSCAN聚类参数（从新Top10选第105行：mcs=300, ms=80, eps=0.2）\n",
    "best_hdb_params = {\n",
    "    \"min_cluster_size\": 150,   # 比Yelp小，适配Beauty子簇拆分\n",
    "    \"min_samples\": 80,         # 与mcs比例合理，平衡核心点与噪声\n",
    "    \"cluster_selection_epsilon\": 0.1,  # 适度合并相似簇\n",
    "    \"metric\": \"euclidean\"\n",
    "}\n",
    "best_clusterer = hdbscan.HDBSCAN(**best_hdb_params)\n",
    "labels_best = best_clusterer.fit_predict(Z_best)  # 簇标签（含噪声-1）\n",
    "probs_best = best_clusterer.probabilities_        # 核心点隶属度\n",
    "\n",
    "# ================== 2. 计算关键指标并打印 ==================\n",
    "# 1. 簇数量（排除噪声）\n",
    "n_clusters = len(set(labels_best)) - (1 if -1 in labels_best else 0)\n",
    "\n",
    "# 2. 噪声比例\n",
    "noise_ratio = np.mean(labels_best == -1)\n",
    "\n",
    "# 3. 轮廓系数（关键修正：用Z_best[non_noise_mask]，和你一致）\n",
    "non_noise_mask = labels_best != -1\n",
    "if sum(non_noise_mask) >= 2 and n_clusters >= 2:\n",
    "    # 输入改为 UMAP降维后的Z_best，与聚类空间一致\n",
    "    sil_score = silhouette_score(\n",
    "        Z_best[non_noise_mask],  # 对齐你的计算逻辑\n",
    "        labels_best[non_noise_mask]\n",
    "    )\n",
    "else:\n",
    "    sil_score = None\n",
    "\n",
    "# 打印结果（此时会和你参数搜索中的高Sil值一致）\n",
    "print(\"===== 聚类关键指标 =====\")\n",
    "print(f\"簇数量: {n_clusters}\")\n",
    "print(f\"轮廓系数 (Silhouette): {sil_score:.4f}\" if sil_score is not None else \"轮廓系数: 无法计算\")\n",
    "print(f\"噪声比例: {noise_ratio:.4f}\")\n",
    "print(\"=======================\")\n",
    "\n",
    "\n",
    "# ================== 2. （Beauty适配）计算加权簇中心 cluster_centers_final ==================\n",
    "# 步骤1：筛选有效簇（排除噪声标签-1）\n",
    "valid_cluster_ids = np.unique(labels_best[labels_best != -1])\n",
    "cluster_centers_final = []\n",
    "\n",
    "# 步骤2：按核心隶属度加权计算中心（Beauty专属调整）\n",
    "min_core_points = 50  # Beauty物品更多，提高最小核心点阈值（比Yelp的30更高）\n",
    "for cid in valid_cluster_ids:\n",
    "    cluster_mask = labels_best == cid\n",
    "    cluster_core_mask = cluster_mask & (probs_best > 0)  # 仅用核心点计算\n",
    "    cluster_embeddings = X_pca[cluster_core_mask]\n",
    "    cluster_probs = probs_best[cluster_core_mask]\n",
    "    \n",
    "    # 过滤过小的簇（Beauty需更严格，避免碎片化）\n",
    "    if len(cluster_embeddings) < min_core_points:\n",
    "        continue\n",
    "    \n",
    "    # 加权平均计算簇中心\n",
    "    weighted_center = np.average(cluster_embeddings, axis=0, weights=cluster_probs)\n",
    "    cluster_centers_final.append(weighted_center)\n",
    "\n",
    "# 转为numpy数组（Beauty预期35-40簇）\n",
    "cluster_centers_final = np.array(cluster_centers_final)\n",
    "print(f\"Beauty有效簇数量：{len(cluster_centers_final)}（已过滤小簇和噪声）\")\n",
    "\n",
    "\n",
    "# ================== 3. （Beauty优化）计算模糊隶属度向量 fuzzy_U_final ==================\n",
    "def compute_fuzzy_membership_beauty(item_emb, cluster_labels, cluster_probs, cluster_centers, fuzzy_m=2.0):\n",
    "    \"\"\"Beauty专属模糊隶属度计算：平衡语义精细度与计算效率\"\"\"\n",
    "    N = len(item_emb)\n",
    "    C = len(cluster_centers)\n",
    "    fuzzy_U = np.zeros((N, C))  # N=Beauty物品数（更大规模）\n",
    "    \n",
    "    # 1. 处理非噪声点（Beauty语义更精细，降低距离衰减系数）\n",
    "    non_noise_mask = cluster_labels != -1\n",
    "    valid_cluster_ids = np.unique(cluster_labels[non_noise_mask])\n",
    "    for i in np.where(non_noise_mask)[0]:\n",
    "        cid = cluster_labels[i]\n",
    "        cid_idx = np.where(valid_cluster_ids == cid)[0]\n",
    "        if len(cid_idx) == 0:\n",
    "            continue\n",
    "        cid_idx = cid_idx[0]\n",
    "        \n",
    "        main_prob = cluster_probs[i]\n",
    "        # 计算距离（Beauty用较弱的距离衰减，保留更多子簇关联）\n",
    "        dists = np.linalg.norm(item_emb[i] - cluster_centers, axis=1)\n",
    "        dists[dists < 1e-8] = 1e-8\n",
    "        inv_dists = 1 / (dists **1.0)  # 衰减更弱，保留更多相关簇\n",
    "        \n",
    "        # 分配隶属度并归一化\n",
    "        fuzzy_U[i, cid_idx] = main_prob * inv_dists[cid_idx]\n",
    "        for k in range(C):\n",
    "            if k != cid_idx:\n",
    "                fuzzy_U[i, k] = (1 - main_prob) * inv_dists[k]\n",
    "        fuzzy_U[i] /= np.sum(fuzzy_U[i])\n",
    "    \n",
    "    # 2. 处理噪声点（Beauty噪声比例适中，用标准模糊分配）\n",
    "    noise_mask = cluster_labels == -1\n",
    "    for i in np.where(noise_mask)[0]:\n",
    "        dists = np.linalg.norm(item_emb[i] - cluster_centers, axis=1)\n",
    "        dists[dists < 1e-8] = 1e-8\n",
    "        inv_dists = 1 / (dists** 1.0)\n",
    "        # 模糊指数2.0（平衡噪声点的多簇关联）\n",
    "        fuzzy_U[i] = inv_dists ** (2 / (fuzzy_m - 1))\n",
    "        fuzzy_U[i] /= np.sum(fuzzy_U[i])\n",
    "    \n",
    "    return fuzzy_U\n",
    "\n",
    "# 调用Beauty专属函数计算模糊隶属度\n",
    "fuzzy_U_final = compute_fuzzy_membership_beauty(\n",
    "    item_emb=X_pca,\n",
    "    cluster_labels=labels_best,\n",
    "    cluster_probs=probs_best,\n",
    "    cluster_centers=cluster_centers_final,\n",
    "    fuzzy_m=2.0  # Beauty语义清晰，无需过高模糊指数\n",
    ")\n",
    "\n",
    "\n",
    "# ================== 4. （Beauty路径）保存文件 ==================\n",
    "save_dir = \"../data/beauty/handled/\"  # 改Beauty保存路径\n",
    "# 保存Beauty聚类结果\n",
    "pickle.dump(labels_best, open(f\"{save_dir}/hdbscan_best_labels.pkl\", \"wb\"))\n",
    "pickle.dump(cluster_centers_final, open(f\"{save_dir}/hdbscan_cluster_centers.pkl\", \"wb\"))\n",
    "pickle.dump(fuzzy_U_final, open(f\"{save_dir}/hdbscan_fuzzy_U.pkl\", \"wb\"))\n",
    "pickle.dump(probs_best, open(f\"{save_dir}/hdbscan_core_probs.pkl\", \"wb\"))\n",
    "\n",
    "# 验证Beauty结果\n",
    "noise_ratio = np.mean(labels_best == -1)\n",
    "print(f\"Beauty聚类结果验证：\")\n",
    "print(f\"- 噪声比例：{noise_ratio:.3f}（Beauty允许≤0.3，符合要求）\")\n",
    "print(f\"- 模糊隶属度矩阵形状：{fuzzy_U_final.shape}（匹配Beauty物品数×簇数）\")\n",
    "print(f\"Beauty所有文件保存成功！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b05fe6db-2664-4eec-949f-cb2c6851bb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_centers_final 形状: (58, 64)\n",
      "fuzzy_U_final 形状: (57289, 58)\n",
      "labels_best 形状: (57289,)\n"
     ]
    }
   ],
   "source": [
    "# 验证变量是否存在且格式正确\n",
    "print(f\"cluster_centers_final 形状: {cluster_centers_final.shape}\")  # 预期 (27, 64)（27个簇，64维嵌入）\n",
    "print(f\"fuzzy_U_final 形状: {fuzzy_U_final.shape}\")                  # 预期 (4722, 27)（4722个物品，27个簇）\n",
    "print(f\"labels_best 形状: {labels_best.shape}\")                      # 预期 (4722,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d8071c-0e67-4e97-bddb-cb24af499a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
